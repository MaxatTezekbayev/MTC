{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "#train CAE+H (1001 MB)\n",
    "CUDA_VISIBLE_DEVICES=1 python main.py --train_CAEH True --epochs 50 --lambd 1e-05 --gamma 1e-07 --numlayers 2 --code_size 196  --code_size2 60   --save_dir_for_CAE saved_weights/196_60_1e-05_1e-07.pth \n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "CUDA_VISIBLE_DEVICES=1 python main.py --train_CAEH False --MTC True  --lambd 1e-05 --gamma 1e-07 --numlayers 2 --code_size 196  --code_size2 60   --pretrained_CAEH saved_weights/196_60_1e-05_1e-07.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_0.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_0.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_0.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_0.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_0.pth  & \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "command='CUDA_VISIBLE_DEVICES={0} python main.py --train_CAEH True   --epochs 60 --lambd {1} --gamma {2} --numlayers 2 --code_size {3} --code_size2 {4} --save_dir_for_CAE saved_weights/{3}_{4}_{1}_{2}.pth  '\n",
    "\n",
    "\n",
    "\n",
    "code_sizes=[392]\n",
    "code_sizes2=[196]\n",
    "\n",
    "lambds=[0.0000001, 0.000001, 0.00001, 0.0001, 0]\n",
    "gammas=[0.0000001, 0.000001, 0.00001, 0.0001, 0]\n",
    "\n",
    "\n",
    "per_gpu=15\n",
    "gpus=[5, 6]\n",
    "i=1\n",
    "for code_size in code_sizes:\n",
    "    for code_size2 in code_sizes2:\n",
    "        for lambd in lambds:\n",
    "            for gamma in gammas:\n",
    "                end=\"& \\n\"\n",
    "                if i%((per_gpu*len(gpus)))==0:\n",
    "                    end=' \\n \\n'\n",
    "\n",
    "                print(command.format(gpus[(i%(per_gpu*len(gpus)))//per_gpu], lambd, gamma, code_size, code_size2),end=end)\n",
    "                i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=3 python main.py --pretrained_CAEH saved_weights/392_196_1e-07_1e-07.pth --MTC True  --lambd 1e-07 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 & \n",
      "CUDA_VISIBLE_DEVICES=3 python main.py --pretrained_CAEH saved_weights/392_196_1e-07_0.pth --MTC True  --lambd 1e-07 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 & \n",
      "CUDA_VISIBLE_DEVICES=3 python main.py --pretrained_CAEH saved_weights/392_196_0_1e-07.pth --MTC True  --lambd 0 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 & \n",
      "CUDA_VISIBLE_DEVICES=3 python main.py --pretrained_CAEH saved_weights/392_196_0_0.pth --MTC True  --lambd 0 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 & \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "command='CUDA_VISIBLE_DEVICES={0} python main.py --pretrained_CAEH saved_weights/{3}_{4}_{1}_{2}.pth --MTC True  --lambd {1} --gamma {2} --numlayers 2 --code_size {3} --code_size2 {4} '\n",
    "\n",
    "\n",
    "\n",
    "code_sizes=[392]\n",
    "code_sizes2=[196]\n",
    "\n",
    "lambds=[0.0000001, 0]\n",
    "gammas=[0.0000001, 0]\n",
    "\n",
    "\n",
    "per_gpu=13\n",
    "gpus=[3, 5, 7]\n",
    "i=1\n",
    "for code_size in code_sizes:\n",
    "    for code_size2 in code_sizes2:\n",
    "        for lambd in lambds:\n",
    "            for gamma in gammas:\n",
    "                end=\"& \\n\"\n",
    "                if i%((per_gpu*len(gpus)))==0:\n",
    "                    end=' \\n \\n'\n",
    "\n",
    "                print(command.format(gpus[(i%(per_gpu*len(gpus)))//per_gpu], lambd, gamma, code_size, code_size2),end=end)\n",
    "                i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 80 --lambd 1e-07 --gamma 1e-07 --batch_size 50 --numlayers 2 --code_size 2000 --code_size2 2000 --save_dir_for_CAE saved_weights/2000_2000_1e-07_1e-07.pth  & \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2000 2000\n",
    "\n",
    "\n",
    "command='CUDA_VISIBLE_DEVICES={0} python main.py --train_CAEH True   --epochs 80 --lambd {1} --gamma {2} --batch_size 50 --numlayers 2 --code_size {3} --code_size2 {4} --save_dir_for_CAE saved_weights/{3}_{4}_{1}_{2}.pth  '\n",
    "\n",
    "\n",
    "\n",
    "code_sizes=[2000]\n",
    "code_sizes2=[2000]\n",
    "\n",
    "lambds=[0.0000001]\n",
    "gammas=[0.0000001]\n",
    "\n",
    "\n",
    "per_gpu=15\n",
    "gpus=[5, 6]\n",
    "i=1\n",
    "for code_size in code_sizes:\n",
    "    for code_size2 in code_sizes2:\n",
    "        for lambd in lambds:\n",
    "            for gamma in gammas:\n",
    "                end=\"& \\n\"\n",
    "                if i%((per_gpu*len(gpus)))==0:\n",
    "                    end=' \\n \\n'\n",
    "\n",
    "                print(command.format(gpus[(i%(per_gpu*len(gpus)))//per_gpu], lambd, gamma, code_size, code_size2),end=end)\n",
    "                i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models import CAE1Layer, CAE2Layer, MTC\n",
    "from utils import cae_h_loss, MTC_loss, calculate_singular_vectors_B, knn_distances, sigmoid\n",
    "import argparse\n",
    "from collections import Counter\n",
    "torch.manual_seed(42)\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "code_size = 196\n",
    "code_size2 = 60\n",
    "\n",
    "batch_size=20\n",
    "image_size = 28\n",
    "dimensionality = image_size*image_size\n",
    "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "M = len(train_dataset)//100\n",
    "k=30\n",
    "indices = torch.randperm(len(train_dataset))[:M]\n",
    "train_z_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(indices))\n",
    "    \n",
    "model = CAE2Layer(dimensionality, [code_size, code_size2])\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model.load_state_dict(torch.load('/home/maxat/Projects/MTC/saved_weights/196_60_1e-05_1e-07.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 20, 784, 784])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_B_alter(model, train_z_loader, k, batch_size, first_time = False):\n",
    "    grad_output=torch.ones(batch_size).cuda()\n",
    "    B=[]\n",
    "    for step, (z, _) in enumerate(train_z_loader):\n",
    "        z = z.view(batch_size, -1).cuda()\n",
    "        z.requires_grad_(True)\n",
    "        recover, code_data= model(z)\n",
    "        dgdx_z=[]   \n",
    "        for i in range(recover.shape[1]):\n",
    "            dgdx_z.append(torch.autograd.grad(outputs=recover[:,i], inputs=z, grad_outputs=grad_output, retain_graph=True)[0])\n",
    "        dgdx_z = torch.reshape(torch.cat(dgdx_z,1), [batch_size, recover.shape[1], z.shape[1]])\n",
    "\n",
    "        u, sigma, v = torch.svd(dgdx_z)\n",
    "        u = u[:, :, :k]\n",
    "        sigma = torch.diag_embed(sigma)[:, :k, :k]\n",
    "        v = torch.transpose(v[:, :, :k],1,2)\n",
    "\n",
    "        b = torch.matmul(u, torch.matmul(sigma, v))\n",
    "        B.append(b.cpu())\n",
    "\n",
    "    B = torch.stack(B)\n",
    "    del dgdx_z\n",
    "    del b\n",
    "    return B\n",
    "\n",
    "B = calculate_B_alter(model, train_z_loader, k, batch_size, first_time = True)\n",
    "B.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784, 784])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_iter = iter(B)\n",
    "next(B_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((30,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[30, -1]' is invalid for input of size 2352",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-bc67c899e80c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-n 5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U=[]\\nfor step, (imgs, _) in enumerate(test_loader):\\n    imgs = imgs.view(batch_size, -1).cuda()\\n    imgs.requires_grad_(True)\\n    recover, code_data= model(imgs)\\n    grad_output=torch.ones(recover.size()).cuda()\\n    dgdx=[]                                                                                        \\n    #print(torch.autograd.grad(outputs=recover, inputs=imgs, grad_outputs=grad_output, retain_graph=True)[0].shape)\\n    Jac = torch.autograd.functional.jacobian(lambda x: model(x)[0], imgs, create_graph=False, strict=True)\\n    Jac = torch.diagonal(Jac, dim1=0, dim2=2).permute(2, 0, 1)\\n#     print(Jac.size)\\n#     Jx=torch.reshape(torch.cat(Jx,1),[batch_size, code_data.shape[1], imgs.shape[1]])\\n#     print(\"Jx\", Jx.shape)\\n#     u1, sigma, v = torch.svd(Jx)\\n#     print(\\'u\\',u1.shape)\\n#     print(\\'sigma\\',sigma.shape)\\n#     print(\\'v\\',v.shape)\\n    break\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2380\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[30, -1]' is invalid for input of size 2352"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5\n",
    "U=[]\n",
    "for step, (imgs, _) in enumerate(test_loader):\n",
    "    imgs = imgs.view(batch_size, -1).cuda()\n",
    "    imgs.requires_grad_(True)\n",
    "    recover, code_data= model(imgs)\n",
    "    grad_output=torch.ones(recover.size()).cuda()\n",
    "    dgdx=[]                                                                                        \n",
    "    #print(torch.autograd.grad(outputs=recover, inputs=imgs, grad_outputs=grad_output, retain_graph=True)[0].shape)\n",
    "    Jac = torch.autograd.functional.jacobian(lambda x: model(x)[0], imgs, create_graph=False, strict=True)\n",
    "    Jac = torch.diagonal(Jac, dim1=0, dim2=2).permute(2, 0, 1)\n",
    "#     print(Jac.size)\n",
    "#     Jx=torch.reshape(torch.cat(Jx,1),[batch_size, code_data.shape[1], imgs.shape[1]])\n",
    "#     print(\"Jx\", Jx.shape)\n",
    "#     u1, sigma, v = torch.svd(Jx)\n",
    "#     print('u',u1.shape)\n",
    "#     print('sigma',sigma.shape)\n",
    "#     print('v',v.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 784, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Jac1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 784, 784])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "U=[]\n",
    "for step, (imgs, _) in enumerate(test_loader):\n",
    "    imgs = imgs.view(batch_size, -1).cuda()\n",
    "    imgs.requires_grad_(True)\n",
    "    recover, code_data= model(imgs)\n",
    "    grad_output=torch.ones(batch_size).cuda()\n",
    "    dgdx=[]   \n",
    "    for i in range(recover.shape[1]):\n",
    "        dgdx.append(torch.autograd.grad(outputs=recover[:,i], inputs=imgs, grad_outputs=grad_output, retain_graph=True)[0])\n",
    "    dgdx=torch.reshape(torch.cat(dgdx,1),[batch_size, recover.shape[1], imgs.shape[1]])\n",
    "    print(dgdx.shape)\n",
    "#     print(\"dgdx\", dgdx.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u (30, 784, 784)\n",
      "s (30, 784)\n",
      "v (30, 784, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "uu,ss,vv = np.linalg.svd(dgdx.cpu().numpy())\n",
    "print(\"u\",uu.shape)\n",
    "print('s',ss.shape)\n",
    "print('v',vv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=40\n",
    "u, sigma, v = torch.svd(dgdx)\n",
    "u = u[:, :, :k]\n",
    "sigma = torch.diag_embed(sigma)[:, :k, :k]\n",
    "v = torch.transpose(v[:, :, :k],1,2)\n",
    "\n",
    "b = torch.matmul(u, torch.matmul(sigma, v)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7.0908e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 5.8376e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 5.6948e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1164e-06,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          5.6298e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 9.7265e-08]],\n",
       "\n",
       "        [[4.2497e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 3.8293e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 3.3691e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.4448e-07,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          3.7891e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 6.0542e-08]],\n",
       "\n",
       "        [[1.0584e+02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 9.3129e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 7.6485e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3279e-06,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          1.2815e-06, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 2.3816e-07]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[6.0989e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 5.9479e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 5.3173e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.4029e-07,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          4.1329e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 7.0362e-08]],\n",
       "\n",
       "        [[5.4274e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 4.3798e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 4.0782e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3089e-06,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          7.2784e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.2873e-07]],\n",
       "\n",
       "        [[7.5122e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 6.5448e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 5.6210e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3640e-06,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          8.2393e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 2.6283e-07]]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.diagonal(sigma).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.49011612e-08,  4.65661287e-09,  3.72529030e-08, ...,\n",
       "          0.00000000e+00,  1.11758709e-08,  2.23517418e-08],\n",
       "        [ 2.94297934e-07, -2.81492248e-07,  1.41561031e-07, ...,\n",
       "          2.79396772e-08,  1.32247806e-07,  4.47034836e-08],\n",
       "        [-9.56331939e-02,  1.15927666e-01, -4.90063503e-02, ...,\n",
       "         -9.00560617e-03, -4.14587781e-02, -3.27650905e-02],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  7.96035603e-02,  4.41132002e-02, ...,\n",
       "          1.18063048e-01,  1.03665143e-03, -1.06260933e-01],\n",
       "        [ 0.00000000e+00, -7.56786913e-02, -5.79742491e-02, ...,\n",
       "          8.13618898e-02, -9.88192409e-02,  5.76680303e-02],\n",
       "        [ 0.00000000e+00, -3.03407423e-02, -3.83895561e-02, ...,\n",
       "          5.59838787e-02,  8.91866069e-03, -1.08216830e-01]],\n",
       "\n",
       "       [[-3.35276127e-08, -2.29105353e-07, -1.93715096e-07, ...,\n",
       "         -4.47034836e-08,  1.49011612e-08,  2.51457095e-08],\n",
       "        [ 1.49011612e-08, -1.67638063e-07,  2.53319740e-07, ...,\n",
       "          2.60770321e-08,  4.84287739e-08,  7.45058060e-09],\n",
       "        [-2.00234354e-08,  1.49011612e-08,  3.21306288e-08, ...,\n",
       "          0.00000000e+00, -7.45058060e-09, -7.45058060e-09],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -1.02112852e-01, -2.45688595e-02, ...,\n",
       "         -6.32360578e-02,  6.59454465e-02,  1.13216676e-02],\n",
       "        [ 0.00000000e+00, -9.84916240e-02,  1.43916905e-01, ...,\n",
       "         -2.72205342e-02, -5.39901517e-02,  2.99524162e-02],\n",
       "        [ 0.00000000e+00, -5.15707210e-02,  4.69148718e-02, ...,\n",
       "          2.12499909e-02,  1.84704196e-02,  8.48987047e-03]],\n",
       "\n",
       "       [[-1.28056854e-08, -6.14672899e-08, -8.19563866e-08, ...,\n",
       "         -7.45058060e-09,  5.58793545e-09, -2.23517418e-08],\n",
       "        [-7.45058060e-09,  1.76019967e-07,  1.89989805e-07, ...,\n",
       "         -3.72529030e-09,  4.09781933e-08,  3.25962901e-08],\n",
       "        [ 5.77419996e-08,  4.28408384e-08, -9.12696123e-08, ...,\n",
       "          1.22381607e-08, -2.87545845e-08, -3.72529030e-09],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  4.31450307e-02, -4.03513685e-02, ...,\n",
       "          2.09190361e-02,  2.58018300e-02, -2.70741917e-02],\n",
       "        [ 0.00000000e+00, -8.21346045e-03, -5.26345707e-02, ...,\n",
       "          2.35338248e-02, -1.94401890e-02,  3.93868573e-02],\n",
       "        [ 0.00000000e+00, -1.16640143e-01,  4.66400832e-02, ...,\n",
       "         -4.94175106e-02,  8.28430243e-03,  8.65413249e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.15557572e-02,  6.27513230e-02,  6.00738898e-02, ...,\n",
       "          2.95793358e-02,  3.98573093e-03, -1.06651813e-01],\n",
       "        [ 4.50138375e-02, -1.03812471e-01, -7.47925118e-02, ...,\n",
       "         -3.28090526e-02,  1.18549064e-01,  3.56472470e-02],\n",
       "        [-6.22548573e-02, -1.17711034e-02, -1.01739511e-01, ...,\n",
       "         -7.86924735e-03,  4.45109233e-02,  3.64757283e-03],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -3.55063602e-02,  1.80364251e-02, ...,\n",
       "          1.16606340e-01, -5.64613938e-02, -9.01358016e-03],\n",
       "        [ 0.00000000e+00, -3.74888778e-02,  7.04760179e-02, ...,\n",
       "         -8.01215842e-02, -5.10664284e-03, -4.52907756e-02],\n",
       "        [ 0.00000000e+00, -4.34975214e-02,  7.67962858e-02, ...,\n",
       "         -5.62445298e-02,  3.30984294e-02,  5.86803677e-03]],\n",
       "\n",
       "       [[-3.72529030e-08, -3.72529030e-08, -1.41561031e-07, ...,\n",
       "          7.45058060e-09, -1.11758709e-08,  1.86264515e-08],\n",
       "        [-4.47034836e-08,  5.58793545e-09, -2.04890966e-08, ...,\n",
       "          3.35276127e-08,  0.00000000e+00,  3.72529030e-09],\n",
       "        [ 8.58203545e-02,  9.77513790e-02, -1.19271159e-01, ...,\n",
       "         -7.92726874e-02,  6.24129660e-02, -8.59977975e-02],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -1.12331502e-01, -2.94368677e-02, ...,\n",
       "         -3.00586447e-02, -6.31037131e-02,  5.84929138e-02],\n",
       "        [ 0.00000000e+00, -3.10432073e-02, -3.08895893e-02, ...,\n",
       "          2.11068131e-02,  3.16915214e-02,  1.25477284e-01],\n",
       "        [ 0.00000000e+00,  8.28439966e-02,  4.31986898e-02, ...,\n",
       "         -7.79343098e-02,  8.29579383e-02, -2.92381011e-02]],\n",
       "\n",
       "       [[-3.35276127e-08,  8.10250640e-08,  1.80676579e-07, ...,\n",
       "          5.58793545e-09, -3.84170562e-09, -6.51925802e-09],\n",
       "        [-7.45058060e-08,  5.86733222e-08,  2.32830644e-09, ...,\n",
       "          2.60770321e-08,  2.04890966e-08,  1.49011612e-08],\n",
       "        [ 1.84021682e-01,  8.35977122e-03, -1.57241315e-01, ...,\n",
       "          3.46536413e-02, -3.88627569e-03,  9.38390265e-04],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -4.91251126e-02,  5.43283187e-02, ...,\n",
       "         -7.23841414e-02,  3.05486880e-02,  3.78315002e-02],\n",
       "        [ 0.00000000e+00, -1.59866214e-01, -1.83140449e-02, ...,\n",
       "         -4.03030701e-02, -2.48217396e-02,  3.22095901e-02],\n",
       "        [ 0.00000000e+00,  2.29242519e-02, -3.68841887e-02, ...,\n",
       "          1.08069414e-02,  5.45447841e-02, -5.96818561e-03]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(v,1,2).cpu().numpy() - vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u torch.Size([30, 784, 784])\n",
      "sigma torch.Size([30, 784])\n",
      "v torch.Size([30, 784, 784])\n"
     ]
    }
   ],
   "source": [
    "u, sigma, v = torch.svd(dgdx, some=False)\n",
    "print('u',u.shape)\n",
    "print('sigma',sigma.shape)\n",
    "print('v',v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
