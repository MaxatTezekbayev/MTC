{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "#train CAE+H (1001 MB)\n",
    "CUDA_VISIBLE_DEVICES=1 python main.py --train_CAEH True --epochs 20 --lambd 1e-05 --gamma 1e-07 --numlayers 2 --code_size 120  --code_size2 60   --save_dir_for_CAE saved_weights/120_60_1e-05_1e-07.pth \n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "CUDA_VISIBLE_DEVICES=1 python main.py --train_CAEH False --MTC True  --lambd 1e-05 --gamma 1e-07 --numlayers 2 --code_size 120 --code_size2 60   --pretrained_CAEH saved_weights/120_60_1e-05_1e-07.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time_model = time.time()\n",
    "time.sleep(1)\n",
    "type(time.time()-start_time_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-07 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-07_0.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-06 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-06_0.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=5 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 1e-05 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_1e-05_0.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0.0001 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0.0001_0.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_1e-07.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 1e-06 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_1e-06.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 1e-05 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_1e-05.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 0.0001 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_0.0001.pth  & \n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --train_CAEH True   --epochs 60 --lambd 0 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 --save_dir_for_CAE saved_weights/392_196_0_0.pth  & \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "command='CUDA_VISIBLE_DEVICES={0} python main.py --train_CAEH True   --epochs 60 --lambd {1} --gamma {2} --numlayers 2 --code_size {3} --code_size2 {4} --save_dir_for_CAE saved_weights/{3}_{4}_{1}_{2}.pth  '\n",
    "\n",
    "\n",
    "\n",
    "code_sizes=[392]\n",
    "code_sizes2=[196]\n",
    "\n",
    "lambds=[0.0000001, 0.000001, 0.00001, 0.0001, 0]\n",
    "gammas=[0.0000001, 0.000001, 0.00001, 0.0001, 0]\n",
    "\n",
    "\n",
    "per_gpu=15\n",
    "gpus=[5, 6]\n",
    "i=1\n",
    "for code_size in code_sizes:\n",
    "    for code_size2 in code_sizes2:\n",
    "        for lambd in lambds:\n",
    "            for gamma in gammas:\n",
    "                end=\"& \\n\"\n",
    "                if i%((per_gpu*len(gpus)))==0:\n",
    "                    end=' \\n \\n'\n",
    "\n",
    "                print(command.format(gpus[(i%(per_gpu*len(gpus)))//per_gpu], lambd, gamma, code_size, code_size2),end=end)\n",
    "                i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=3 python main.py --pretrained_CAEH saved_weights/392_196_1e-07_1e-07.pth --MTC True  --lambd 1e-07 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 & \n",
      "CUDA_VISIBLE_DEVICES=3 python main.py --pretrained_CAEH saved_weights/392_196_1e-07_0.pth --MTC True  --lambd 1e-07 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 & \n",
      "CUDA_VISIBLE_DEVICES=3 python main.py --pretrained_CAEH saved_weights/392_196_0_1e-07.pth --MTC True  --lambd 0 --gamma 1e-07 --numlayers 2 --code_size 392 --code_size2 196 & \n",
      "CUDA_VISIBLE_DEVICES=3 python main.py --pretrained_CAEH saved_weights/392_196_0_0.pth --MTC True  --lambd 0 --gamma 0 --numlayers 2 --code_size 392 --code_size2 196 & \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "command='CUDA_VISIBLE_DEVICES={0} python main.py --pretrained_CAEH saved_weights/{3}_{4}_{1}_{2}.pth --MTC True  --lambd {1} --gamma {2} --numlayers 2 --code_size {3} --code_size2 {4} '\n",
    "\n",
    "\n",
    "\n",
    "code_sizes=[392]\n",
    "code_sizes2=[196]\n",
    "\n",
    "lambds=[0.0000001, 0]\n",
    "gammas=[0.0000001, 0]\n",
    "\n",
    "\n",
    "per_gpu=13\n",
    "gpus=[3, 5, 7]\n",
    "i=1\n",
    "for code_size in code_sizes:\n",
    "    for code_size2 in code_sizes2:\n",
    "        for lambd in lambds:\n",
    "            for gamma in gammas:\n",
    "                end=\"& \\n\"\n",
    "                if i%((per_gpu*len(gpus)))==0:\n",
    "                    end=' \\n \\n'\n",
    "\n",
    "                print(command.format(gpus[(i%(per_gpu*len(gpus)))//per_gpu], lambd, gamma, code_size, code_size2),end=end)\n",
    "                i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=3 python main.py --train_CAEH True   --epochs 80 --lambd 1e-07 --gamma 1e-07 --batch_size 150 --numlayers 2 --code_size 2000 --code_size2 2000 --save_dir_for_CAE saved_weights/2000_2000_1e-07_1e-07.pth  & \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2000 2000\n",
    "\n",
    "\n",
    "command='CUDA_VISIBLE_DEVICES={0} python main.py --train_CAEH True   --epochs 80 --lambd {1} --gamma {2} --batch_size 150 --numlayers 2 --code_size {3} --code_size2 {4} --save_dir_for_CAE saved_weights/{3}_{4}_{1}_{2}.pth  '\n",
    "\n",
    "\n",
    "\n",
    "code_sizes=[2000]\n",
    "code_sizes2=[2000]\n",
    "\n",
    "lambds=[0.0000001]\n",
    "gammas=[0.0000001]\n",
    "\n",
    "\n",
    "per_gpu=15\n",
    "gpus=[3, 6]\n",
    "i=1\n",
    "for code_size in code_sizes:\n",
    "    for code_size2 in code_sizes2:\n",
    "        for lambd in lambds:\n",
    "            for gamma in gammas:\n",
    "                end=\"& \\n\"\n",
    "                if i%((per_gpu*len(gpus)))==0:\n",
    "                    end=' \\n \\n'\n",
    "\n",
    "                print(command.format(gpus[(i%(per_gpu*len(gpus)))//per_gpu], lambd, gamma, code_size, code_size2),end=end)\n",
    "                i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=2 python main.py --ALTER True --batch_size 20 --M 60 --epochs 40 --lambd 10.0 --gamma 1.0 --numlayers 2 --code_size 120 --code_size2 60 --save_dir_for_ALTER saved_weights/alter_120_60_10.0_1.0.pth & \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "command='CUDA_VISIBLE_DEVICES={0} python main.py --ALTER True --batch_size 20 --M 60 --epochs 40 --lambd {1} --gamma {2} --numlayers 2 --code_size {3} --code_size2 {4} --save_dir_for_ALTER saved_weights/alter_{3}_{4}_{1}_{2}.pth '\n",
    "\n",
    "\n",
    "\n",
    "code_sizes=[120]\n",
    "code_sizes2=[60]\n",
    "\n",
    "lambds=[10.0]\n",
    "gammas=[1.0]\n",
    "\n",
    "\n",
    "per_gpu=15\n",
    "gpus=[2]\n",
    "i=1\n",
    "for code_size in code_sizes:\n",
    "    for code_size2 in code_sizes2:\n",
    "        for lambd in lambds:\n",
    "            for gamma in gammas:\n",
    "                end=\"& \\n\"\n",
    "                if i%((per_gpu*len(gpus)))==0:\n",
    "                    end=' \\n \\n'\n",
    "\n",
    "                print(command.format(gpus[(i%(per_gpu*len(gpus)))//per_gpu], lambd, gamma, code_size, code_size2),end=end)\n",
    "                i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsf\n"
     ]
    }
   ],
   "source": [
    "a=1\n",
    "b=2\n",
    "if (a is not None) and (b is not None):\n",
    "    print('dsf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models import  CAE2Layer, MTC,  ALTER2Layer\n",
    "from utils import cae_h_loss, MTC_loss, calculate_singular_vectors_B, knn_distances, sigmoid\n",
    "import argparse\n",
    "from collections import Counter\n",
    "torch.manual_seed(42)\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "code_size = 196\n",
    "code_size2 = 60\n",
    "\n",
    "batch_size=20\n",
    "image_size = 28\n",
    "dimensionality = image_size*image_size\n",
    "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "M = len(train_dataset)//100\n",
    "k=30\n",
    "indices = torch.randperm(len(train_dataset))[:M]\n",
    "train_z_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(indices))\n",
    "    \n",
    "model = ALTER2Layer(dimensionality, [code_size, code_size2])\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model.load_state_dict(torch.load('/home/maxat/Projects/MTC/saved_weights/196_60_1e-05_1e-07.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 1, 28, 28]), tensor([0.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.zeros((len(train_z_loader),1))\n",
    "z_b_iter = iter(zip(train_z_loader,B))\n",
    "(z,_), b = next(z_b_iter)\n",
    "z.shape, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "for step, (imgs, _) in enumerate(test_loader):\n",
    "    imgs = imgs.view(batch_size, -1).cuda()\n",
    "    imgs.requires_grad_(True)\n",
    "    recover, code_data, Jac = model(imgs, calculate_jacobian = True)\n",
    "    sigma_prime1 = torch.mul(1.0 - code_data[0], code_data[0])\n",
    "    print(sigma_prime1.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_batch, S_batch, V_batch = torch.svd(Jac.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2596290e-09, -1.4551915e-11, -2.3283064e-10, ...,\n",
       "        -1.3969839e-09, -3.4924597e-10,  1.5461410e-10],\n",
       "       [-2.2351742e-08,  2.7939677e-09, -1.0244548e-08, ...,\n",
       "        -4.1909516e-09, -7.4505806e-09,  1.1175871e-08],\n",
       "       [ 0.0000000e+00, -2.2118911e-09,  9.3132257e-10, ...,\n",
       "        -1.8626451e-09,  1.3969839e-09,  0.0000000e+00],\n",
       "       ...,\n",
       "       [-1.8626451e-09,  1.9790605e-09, -2.7939677e-09, ...,\n",
       "         3.7252903e-09,  9.3132257e-10,  5.3551048e-09],\n",
       "       [ 7.4505806e-09, -4.6566129e-10,  1.8626451e-09, ...,\n",
       "         2.3283064e-10,  9.3132257e-10, -3.7252903e-09],\n",
       "       [ 3.7252903e-09, -7.4505806e-09, -2.2351742e-08, ...,\n",
       "         7.4505806e-09,  1.4901161e-08, -2.9336661e-08]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.matmul(u[0], np.matmul(np.diag(s[0]),v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_batch2, S_batch2, V_batch2 = torch.svd(Jac.cuda())\n",
    "U_batch2= U_batch2.cpu()\n",
    "S_batch2=S_batch2.cpu()\n",
    "V_batch2=V_batch2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = torch.matmul(U_batch[:, :, :k], torch.matmul(torch.diag_embed(S_batch)[:, :k, :k], torch.transpose(V_batch[:, :, :k],1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "B2 = torch.matmul(U_batch2[:, :, :k], torch.matmul(torch.diag_embed(S_batch2)[:, :k, :k], torch.transpose(V_batch2[:, :, :k],1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.6394e-08, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(B2-B1).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(Jac.cpu().detach().numpy(), full_matrices = False)\n",
    "u = torch.from_numpy(u)\n",
    "s = torch.from_numpy(s)\n",
    "v = torch.from_numpy(v)\n",
    "B3_np = torch.matmul(u[:, :, :k], torch.matmul(torch.diag_embed(s)[:, :k, :k], v[:, :k, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1486e-08, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(B2-B3_np).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.6803e+01, 6.5780e+01, 5.5559e+01,  ..., 2.3149e-10, 1.8905e-10,\n",
       "         4.4759e-11],\n",
       "        [8.7539e+01, 6.6931e+01, 5.4841e+01,  ..., 1.3220e-10, 7.4583e-11,\n",
       "         4.9645e-11],\n",
       "        [7.2340e+01, 7.0377e+01, 4.6378e+01,  ..., 2.3193e-10, 1.3434e-10,\n",
       "         1.2477e-10],\n",
       "        ...,\n",
       "        [8.0047e+01, 6.5851e+01, 5.0935e+01,  ..., 2.7242e-10, 2.3664e-10,\n",
       "         4.2624e-11],\n",
       "        [8.3150e+01, 6.4367e+01, 5.2676e+01,  ..., 1.6590e-10, 7.1220e-11,\n",
       "         1.6624e-11],\n",
       "        [8.4814e+01, 7.6499e+01, 5.2942e+01,  ..., 2.3836e-10, 1.4220e-10,\n",
       "         7.6314e-11]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.6803e+01, 6.5780e+01, 5.5559e+01,  ..., 1.5632e-06, 1.5547e-06,\n",
       "         4.4148e-07],\n",
       "        [8.7539e+01, 6.6931e+01, 5.4841e+01,  ..., 1.5926e-06, 9.5613e-07,\n",
       "         2.5980e-07],\n",
       "        [7.2340e+01, 7.0377e+01, 4.6378e+01,  ..., 1.5803e-06, 5.6798e-07,\n",
       "         4.0035e-07],\n",
       "        ...,\n",
       "        [8.0047e+01, 6.5851e+01, 5.0935e+01,  ..., 1.6771e-06, 9.7161e-07,\n",
       "         2.9124e-07],\n",
       "        [8.3150e+01, 6.4367e+01, 5.2676e+01,  ..., 1.8033e-06, 1.1080e-06,\n",
       "         2.9142e-07],\n",
       "        [8.4814e+01, 7.6499e+01, 5.2942e+01,  ..., 2.0193e-06, 1.1352e-06,\n",
       "         2.9182e-07]], grad_fn=<SvdBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_data1 = model.sigmoid(torch.matmul(imgs, model.W1.t()) + model.b1)\n",
    "code_data2 = model.sigmoid(torch.matmul(code_data1, model.W2.t()) + model.b2)\n",
    "#decode\n",
    "code_data3 = model.sigmoid(torch.matmul(code_data2, model.W2) + model.b3)\n",
    "recover = torch.matmul(code_data3, model.W1) + model.b_r\n",
    "\n",
    "Jac4 = []\n",
    "for i in range(imgs.shape[0]): \n",
    "    diag_sigma_prime1 = torch.diag( torch.mul(1.0 - code_data1[i], code_data1[i]))\n",
    "    grad_1 = torch.matmul(model.W1.t(), diag_sigma_prime1)\n",
    "\n",
    "    diag_sigma_prime2 = torch.diag( torch.mul(1.0 - code_data2[i], code_data2[i]))\n",
    "    grad_2 = torch.matmul(model.W2.t(), diag_sigma_prime2)\n",
    "\n",
    "    diag_sigma_prime3  = torch.diag( torch.mul(1.0 - code_data3[i], code_data3[i]))\n",
    "    grad_3 = torch.matmul(model.W2, diag_sigma_prime3)\n",
    "\n",
    "    grad_4 = model.W1\n",
    "    Jac4.append(torch.matmul(grad_1, torch.matmul(grad_2, torch.matmul(grad_3, grad_4))))\n",
    "Jac4 = torch.reshape(torch.cat(Jac4,1), [imgs.shape[0], recover.shape[1], imgs.shape[1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.6394e-08, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_batch4, S_batch4, V_batch4 = torch.svd(Jac4.cpu())\n",
    "B4 = torch.matmul(U_batch4[:, :, :k], torch.matmul(torch.diag_embed(S_batch4)[:, :k, :k], torch.transpose(V_batch4[:, :, :k],1,2)))\n",
    "(B2-B4).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19889823\n",
      "tensor(0.0930, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A_matrix = []\n",
    "B_matrix = []\n",
    "C_matrix = []\n",
    "for i in range(imgs.shape[0]): \n",
    "    diag_sigma_prime1 = torch.diag( torch.mul(1.0 - code_data1[i], code_data1[i]))\n",
    "    grad_1 = torch.matmul(model.W1.t(), diag_sigma_prime1)\n",
    "\n",
    "    diag_sigma_prime2 = torch.diag( torch.mul(1.0 - code_data2[i], code_data2[i]))\n",
    "    grad_2 = torch.matmul(model.W2.t(), diag_sigma_prime2)\n",
    "\n",
    "    diag_sigma_prime3  = torch.diag( torch.mul(1.0 - code_data3[i], code_data3[i]))\n",
    "    grad_3 = torch.matmul(model.W2, diag_sigma_prime3)\n",
    "\n",
    "    A_matrix.append(grad_1)\n",
    "    B_matrix.append(grad_2)\n",
    "    C_matrix.append(grad_3)\n",
    "A_matrix = torch.reshape(torch.cat(A_matrix, 1),[imgs.shape[0], grad_1.shape[0], grad_1.shape[1]])\n",
    "B_matrix = torch.reshape(torch.cat(B_matrix, 1),[imgs.shape[0], grad_2.shape[0], grad_2.shape[1]])\n",
    "C_matrix = torch.reshape(torch.cat(C_matrix, 1),[imgs.shape[0], grad_3.shape[0], grad_3.shape[1]])\n",
    "\n",
    "            \n",
    "def svd_product(A, U, S, VH): # A*U*S*VH\n",
    "    Q, R = torch.qr(torch.matmul(A, U))\n",
    "    u_temp, s_temp, vh_temp = torch.svd(torch.matmul(R, torch.diag(S)))\n",
    "    return [torch.matmul(Q, u_temp), s_temp, torch.matmul(vh_temp.T,VH)]\n",
    "\n",
    "def svd_drei(A, B, C, D): # A*B*C*D\n",
    "    U_temp, S_temp, VH_temp = torch.svd(torch.matmul(C, D))\n",
    "    return svd_product(torch.matmul(A, B), U_temp, S_temp, VH_temp.T)\n",
    "\n",
    "# def svd_drei(A, B, C, U, S, VH): # A*B*C*U*S*VH\n",
    "#     U1, S1, VH1 = svd_product(C, U, S, VH)\n",
    "#     U2, S2, VH2 = svd_product(B, U1, S1, VH1)\n",
    "#     return svd_product(A, U2, S2, VH2)\n",
    "# def svd_product_np(A, U, S, VH): # A*U*S*VH\n",
    "    \n",
    "\n",
    "def svd_drei_np(A, B, C, D): # A*B*C*U*S*VH\n",
    "    U, S, VH = np.linalg.svd(np.matmul(C, D), full_matrices=False)\n",
    "    Q, R = np.linalg.qr(np.matmul(np.matmul(A, B), U), mode='complete')\n",
    "    u, s, vh = np.linalg.svd(np.matmul(R, np.diag(S)), full_matrices=False)\n",
    "   \n",
    "    return [np.matmul(np.matmul(Q,u), np.matmul(np.diag(s), np.matmul(vh, VH))), np.matmul(Q,u), s, np.matmul(vh, VH)]\n",
    "\n",
    "B5_np=[]\n",
    "# U_W4, S_W4, VH_W4 = torch.svd(model.W1.clone().cpu())\n",
    "for i in range(len(A_matrix)):\n",
    "#     u, s, vh = svd_drei(A_matrix[i].cpu(), B_matrix[i].cpu(), C_matrix[i].cpu(), U_W4, S_W4, VH_W4.T)\n",
    "    BA, u, s, vh = svd_drei_np(A_matrix[i].cpu().detach().numpy(), B_matrix[i].cpu().detach().numpy(), C_matrix[i].cpu().detach().numpy(), model.W1.clone().cpu().detach().numpy())\n",
    "    b = np.matmul(u[:, :k], np.matmul(np.diag(s)[:k, :k], vh[:k, :]))\n",
    "    \n",
    "#     break\n",
    "    B5_np.append(b)\n",
    "B5_np = np.stack(B5_np)\n",
    "\n",
    "# B5=[]\n",
    "# U_W4, S_W4, VH_W4 = torch.svd(model.W1.clone().cpu())\n",
    "\n",
    "# U_ = []\n",
    "# S_ = []\n",
    "# V_ = []\n",
    "# for i in range(len(A_matrix)):\n",
    "# #     u, s, vh = svd_drei(A_matrix[i].cpu(), B_matrix[i].cpu(), C_matrix[i].cpu(), U_W4, S_W4, VH_W4.T)\n",
    "#     u, s, vh = svd_drei(A_matrix[i].cpu(), B_matrix[i].cpu(), C_matrix[i].cpu(), model.W1.clone().cpu())\n",
    "#     b = torch.matmul(u[:, :k], torch.matmul(torch.diag_embed(s)[:k, :k], vh[:k, :]))\n",
    "#     B5.append(b)\n",
    "# B5 = torch.stack(B5)\n",
    "# print(np.abs((U_batch2[0].cpu().detach().numpy()-u)).mean())\n",
    "# print(np.abs((B1[0].cpu().detach().numpy()-b)).mean())\n",
    "print(np.abs((B1.cpu().detach().numpy()-B5_np)).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-4.28766012e-02, -4.71626967e-02, -2.02330321e-01, ...,\n",
       "          1.26846908e-02,  1.20466866e-01, -6.74422458e-02],\n",
       "        [ 1.04582503e-01, -6.49235696e-02,  3.12796801e-01, ...,\n",
       "         -2.58644193e-01, -1.41818658e-01, -9.75129753e-03],\n",
       "        [-4.94709089e-02,  4.77489009e-02, -1.52220160e-01, ...,\n",
       "          2.02409416e-01,  4.36485372e-02,  2.68085673e-02],\n",
       "        ...,\n",
       "        [ 2.95491647e-02,  3.77730979e-03,  2.82701552e-01, ...,\n",
       "         -5.53249381e-02, -1.62406504e-01,  7.73949176e-02],\n",
       "        [ 3.31216305e-01,  1.39407814e-02,  1.65196210e-01, ...,\n",
       "         -3.22532982e-01, -3.54972444e-02, -1.38275564e-01],\n",
       "        [-7.11001903e-02, -5.67256212e-02, -3.00399482e-01, ...,\n",
       "         -1.26848504e-01,  1.30473986e-01, -2.36352712e-01]],\n",
       "\n",
       "       [[-1.82887390e-01, -1.94001302e-01, -2.66330868e-01, ...,\n",
       "         -1.92138739e-02,  1.88107491e-01, -9.71195996e-02],\n",
       "        [ 1.70968339e-01, -7.19793886e-02,  3.00582618e-01, ...,\n",
       "         -2.56501615e-01, -1.17008388e-01, -4.50870693e-02],\n",
       "        [ 1.38835818e-01, -2.08759457e-02, -6.99374437e-01, ...,\n",
       "         -2.66044348e-01, -1.14027366e-01,  4.15673822e-01],\n",
       "        ...,\n",
       "        [ 2.65628332e-05,  2.25415407e-03,  2.69551754e-01, ...,\n",
       "         -4.03389707e-02, -1.73440620e-01,  8.04894865e-02],\n",
       "        [ 4.73843932e-01, -1.75731890e-02, -1.29928738e-01, ...,\n",
       "         -6.46733880e-01, -1.56413823e-01,  8.90562087e-02],\n",
       "        [ 2.84001082e-02, -9.28454697e-02, -2.28560716e-01, ...,\n",
       "         -1.45979866e-01,  2.08170086e-01, -2.43749186e-01]],\n",
       "\n",
       "       [[ 2.56328195e-01,  1.19114697e-01,  3.20005447e-01, ...,\n",
       "          8.51910263e-02,  1.22029595e-01, -1.73130095e-01],\n",
       "        [ 4.30581808e-01, -2.46653199e-01, -3.23652804e-01, ...,\n",
       "         -3.30851853e-01, -2.82340795e-01,  2.08432436e-01],\n",
       "        [-5.84153682e-02,  1.87125027e-01,  2.63410062e-02, ...,\n",
       "          4.96018320e-01, -4.53178920e-02, -1.16307363e-01],\n",
       "        ...,\n",
       "        [ 2.64126379e-02, -8.20317306e-03,  2.10454941e-01, ...,\n",
       "         -3.33105214e-02, -1.96959496e-01,  1.04888417e-01],\n",
       "        [ 3.68281096e-01,  1.89181626e-01,  5.61098278e-01, ...,\n",
       "         -6.43637776e-02, -5.49321808e-02, -3.70322734e-01],\n",
       "        [-6.72414303e-02, -7.46280178e-02, -1.15914673e-01, ...,\n",
       "         -5.78888506e-02,  2.34008878e-01, -4.51821804e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.79422164e-01, -1.92570880e-01, -5.66648960e-01, ...,\n",
       "         -6.06757440e-02,  1.11316375e-01, -1.55738816e-02],\n",
       "        [ 1.95117831e-01, -1.37714177e-01,  1.45034775e-01, ...,\n",
       "         -3.33422840e-01, -9.61758643e-02,  6.00930527e-02],\n",
       "        [-7.29308128e-02,  3.44469845e-02, -1.93670526e-01, ...,\n",
       "          1.92310169e-01,  4.21408713e-02,  7.50854909e-02],\n",
       "        ...,\n",
       "        [-4.08457825e-03,  3.01385839e-02,  3.64337862e-01, ...,\n",
       "         -2.29647793e-02, -1.71436474e-01,  9.57258046e-03],\n",
       "        [ 3.73818278e-01,  2.11758241e-02,  1.72830909e-01, ...,\n",
       "         -2.89734423e-01, -3.08206771e-02, -2.02040404e-01],\n",
       "        [-1.20547004e-01, -9.97350737e-02, -2.49665752e-01, ...,\n",
       "         -5.03059924e-02,  2.41361797e-01, -4.13177490e-01]],\n",
       "\n",
       "       [[-6.61452562e-02, -5.50006963e-02, -2.04598099e-01, ...,\n",
       "          1.78552400e-02,  1.26333043e-01, -4.45266627e-02],\n",
       "        [ 8.76635313e-04, -4.26354147e-02, -2.41158903e-02, ...,\n",
       "         -5.67649484e-01, -1.60151392e-01,  2.09010452e-01],\n",
       "        [-7.60234147e-02,  8.71098787e-02, -5.91713935e-02, ...,\n",
       "          2.33117357e-01,  2.88917199e-02,  9.54356790e-03],\n",
       "        ...,\n",
       "        [ 1.90293476e-01, -1.01862624e-02,  5.08465290e-01, ...,\n",
       "          1.33092940e-01, -2.12128937e-01,  1.37357518e-01],\n",
       "        [ 3.19193959e-01,  7.36732930e-02,  3.49620134e-01, ...,\n",
       "         -2.84806818e-01, -7.70888776e-02, -1.96765199e-01],\n",
       "        [-6.19437918e-02, -3.81989628e-01, -8.38641047e-01, ...,\n",
       "         -5.12079597e-01,  2.19799295e-01, -5.42943925e-02]],\n",
       "\n",
       "       [[-4.94956560e-02, -3.75017524e-02, -2.21412614e-01, ...,\n",
       "          4.88982070e-03,  1.07805386e-01, -5.88889681e-02],\n",
       "        [ 3.15465957e-01,  1.36012316e-01,  3.08292985e-01, ...,\n",
       "         -6.71849072e-01, -3.11170995e-01,  1.81299031e-01],\n",
       "        [-4.01423305e-01,  7.93766603e-02, -7.93438613e-01, ...,\n",
       "         -4.45549875e-01,  2.63543904e-01,  4.09215301e-01],\n",
       "        ...,\n",
       "        [-1.54932037e-01,  1.68592200e-01,  7.15230823e-01, ...,\n",
       "          1.58081576e-03, -1.00125864e-01, -8.90893489e-02],\n",
       "        [ 2.09430650e-01,  6.89497143e-02,  1.79358453e-01, ...,\n",
       "         -3.52744520e-01,  2.30067223e-02, -1.08481608e-01],\n",
       "        [-2.54788008e-02, -1.46477655e-01, -3.74382645e-01, ...,\n",
       "         -1.37571365e-01,  1.89646900e-01, -2.32516214e-01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jac.cpu().detach().numpy()- BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-47e0fe0419cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Q' is not defined"
     ]
    }
   ],
   "source": [
    "np.matmul(np.matmul(Q,u), np.matmul(np.diag(s), np.matmul(vh, VH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-18.7188,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   5.7563,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000, -15.6516,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   6.6253,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,  18.2728,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  15.6532,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  14.2968,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          11.7051,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,  10.6652,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,  10.1267,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,  10.2749,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   9.6197,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   9.0057,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   8.8082,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           6.8548,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   6.5595,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   5.7828,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   5.5144,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   5.0744,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   4.7052,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   4.3494,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           3.6874,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   3.3582,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   3.1852,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   2.6906,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   2.6753,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   2.4322,   0.0000,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   2.1855,\n",
       "           0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           1.9222,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   1.6447]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag_embed(S_batch2[-1])[:k, :k] - torch.diag_embed(s)[:k, :k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.6394e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((B4-B2).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.6394e-08, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=5\n",
    "b=3\n",
    "del a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 20, 784, 784])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_B_alter(model, train_z_loader, k, batch_size, first_time = False):\n",
    "    grad_output=torch.ones(batch_size).cuda()\n",
    "    B=[]\n",
    "    for step, (imgs, _) in enumerate(test_loader):\n",
    "        imgs = imgs.view(batch_size, -1).cuda()\n",
    "        imgs.requires_grad_(True)\n",
    "        recover, code_data= model(imgs)\n",
    "    \n",
    "        z = z.view(batch_size, -1).cuda()\n",
    "        z.requires_grad_(True)\n",
    "        recover, code_data= model(z)\n",
    "        dgdx_z=[]   \n",
    "        for i in range(recover.shape[1]):\n",
    "            dgdx_z.append(torch.autograd.grad(outputs=recover[:,i], inputs=z, grad_outputs=grad_output, retain_graph=True)[0])\n",
    "        dgdx_z = torch.reshape(torch.cat(dgdx_z,1), [batch_size, recover.shape[1], z.shape[1]])\n",
    "\n",
    "        u, sigma, v = torch.svd(dgdx_z)\n",
    "        u = u[:, :, :k]\n",
    "        sigma = torch.diag_embed(sigma)[:, :k, :k]\n",
    "        v = torch.transpose(v[:, :, :k],1,2)\n",
    "\n",
    "        b = torch.matmul(u, torch.matmul(sigma, v))\n",
    "        B.append(b.cpu())\n",
    "\n",
    "    B = torch.stack(B)\n",
    "    del dgdx_z\n",
    "    del b\n",
    "    return B\n",
    "\n",
    "B = calculate_B_alter(model, train_z_loader, k, batch_size, first_time = True)\n",
    "B.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784, 784])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_iter = iter(B)\n",
    "next(B_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((30,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[30, -1]' is invalid for input of size 2352",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-bc67c899e80c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-n 5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U=[]\\nfor step, (imgs, _) in enumerate(test_loader):\\n    imgs = imgs.view(batch_size, -1).cuda()\\n    imgs.requires_grad_(True)\\n    recover, code_data= model(imgs)\\n    grad_output=torch.ones(recover.size()).cuda()\\n    dgdx=[]                                                                                        \\n    #print(torch.autograd.grad(outputs=recover, inputs=imgs, grad_outputs=grad_output, retain_graph=True)[0].shape)\\n    Jac = torch.autograd.functional.jacobian(lambda x: model(x)[0], imgs, create_graph=False, strict=True)\\n    Jac = torch.diagonal(Jac, dim1=0, dim2=2).permute(2, 0, 1)\\n#     print(Jac.size)\\n#     Jx=torch.reshape(torch.cat(Jx,1),[batch_size, code_data.shape[1], imgs.shape[1]])\\n#     print(\"Jx\", Jx.shape)\\n#     u1, sigma, v = torch.svd(Jx)\\n#     print(\\'u\\',u1.shape)\\n#     print(\\'sigma\\',sigma.shape)\\n#     print(\\'v\\',v.shape)\\n    break\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2380\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyterhub/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[30, -1]' is invalid for input of size 2352"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5\n",
    "U=[]\n",
    "for step, (imgs, _) in enumerate(test_loader):\n",
    "    imgs = imgs.view(batch_size, -1).cuda()\n",
    "    imgs.requires_grad_(True)\n",
    "    recover, code_data= model(imgs)\n",
    "    grad_output=torch.ones(recover.size()).cuda()\n",
    "    dgdx=[]                                                                                        \n",
    "    #print(torch.autograd.grad(outputs=recover, inputs=imgs, grad_outputs=grad_output, retain_graph=True)[0].shape)\n",
    "    Jac = torch.autograd.functional.jacobian(lambda x: model(x)[0], imgs, create_graph=False, strict=True)\n",
    "    Jac = torch.diagonal(Jac, dim1=0, dim2=2).permute(2, 0, 1)\n",
    "#     print(Jac.size)\n",
    "#     Jx=torch.reshape(torch.cat(Jx,1),[batch_size, code_data.shape[1], imgs.shape[1]])\n",
    "#     print(\"Jx\", Jx.shape)\n",
    "#     u1, sigma, v = torch.svd(Jx)\n",
    "#     print('u',u1.shape)\n",
    "#     print('sigma',sigma.shape)\n",
    "#     print('v',v.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 784, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Jac1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 784, 784])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "U=[]\n",
    "for step, (imgs, _) in enumerate(test_loader):\n",
    "    imgs = imgs.view(batch_size, -1).cuda()\n",
    "    imgs.requires_grad_(True)\n",
    "    recover, code_data= model(imgs)\n",
    "    grad_output=torch.ones(batch_size).cuda()\n",
    "    dgdx=[]   \n",
    "    for i in range(recover.shape[1]):\n",
    "        dgdx.append(torch.autograd.grad(outputs=recover[:,i], inputs=imgs, grad_outputs=grad_output, retain_graph=True)[0])\n",
    "    dgdx=torch.reshape(torch.cat(dgdx,1),[batch_size, recover.shape[1], imgs.shape[1]])\n",
    "    print(dgdx.shape)\n",
    "#     print(\"dgdx\", dgdx.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u (30, 784, 784)\n",
      "s (30, 784)\n",
      "v (30, 784, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "uu,ss,vv = np.linalg.svd(dgdx.cpu().numpy())\n",
    "print(\"u\",uu.shape)\n",
    "print('s',ss.shape)\n",
    "print('v',vv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=40\n",
    "u, sigma, v = torch.svd(dgdx)\n",
    "u = u[:, :, :k]\n",
    "sigma = torch.diag_embed(sigma)[:, :k, :k]\n",
    "v = torch.transpose(v[:, :, :k],1,2)\n",
    "\n",
    "b = torch.matmul(u, torch.matmul(sigma, v)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7.0908e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 5.8376e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 5.6948e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1164e-06,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          5.6298e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 9.7265e-08]],\n",
       "\n",
       "        [[4.2497e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 3.8293e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 3.3691e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.4448e-07,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          3.7891e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 6.0542e-08]],\n",
       "\n",
       "        [[1.0584e+02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 9.3129e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 7.6485e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3279e-06,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          1.2815e-06, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 2.3816e-07]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[6.0989e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 5.9479e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 5.3173e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.4029e-07,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          4.1329e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 7.0362e-08]],\n",
       "\n",
       "        [[5.4274e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 4.3798e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 4.0782e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3089e-06,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          7.2784e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.2873e-07]],\n",
       "\n",
       "        [[7.5122e+01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 6.5448e+01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 5.6210e+01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3640e-06,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          8.2393e-07, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 2.6283e-07]]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.diagonal(sigma).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.49011612e-08,  4.65661287e-09,  3.72529030e-08, ...,\n",
       "          0.00000000e+00,  1.11758709e-08,  2.23517418e-08],\n",
       "        [ 2.94297934e-07, -2.81492248e-07,  1.41561031e-07, ...,\n",
       "          2.79396772e-08,  1.32247806e-07,  4.47034836e-08],\n",
       "        [-9.56331939e-02,  1.15927666e-01, -4.90063503e-02, ...,\n",
       "         -9.00560617e-03, -4.14587781e-02, -3.27650905e-02],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  7.96035603e-02,  4.41132002e-02, ...,\n",
       "          1.18063048e-01,  1.03665143e-03, -1.06260933e-01],\n",
       "        [ 0.00000000e+00, -7.56786913e-02, -5.79742491e-02, ...,\n",
       "          8.13618898e-02, -9.88192409e-02,  5.76680303e-02],\n",
       "        [ 0.00000000e+00, -3.03407423e-02, -3.83895561e-02, ...,\n",
       "          5.59838787e-02,  8.91866069e-03, -1.08216830e-01]],\n",
       "\n",
       "       [[-3.35276127e-08, -2.29105353e-07, -1.93715096e-07, ...,\n",
       "         -4.47034836e-08,  1.49011612e-08,  2.51457095e-08],\n",
       "        [ 1.49011612e-08, -1.67638063e-07,  2.53319740e-07, ...,\n",
       "          2.60770321e-08,  4.84287739e-08,  7.45058060e-09],\n",
       "        [-2.00234354e-08,  1.49011612e-08,  3.21306288e-08, ...,\n",
       "          0.00000000e+00, -7.45058060e-09, -7.45058060e-09],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -1.02112852e-01, -2.45688595e-02, ...,\n",
       "         -6.32360578e-02,  6.59454465e-02,  1.13216676e-02],\n",
       "        [ 0.00000000e+00, -9.84916240e-02,  1.43916905e-01, ...,\n",
       "         -2.72205342e-02, -5.39901517e-02,  2.99524162e-02],\n",
       "        [ 0.00000000e+00, -5.15707210e-02,  4.69148718e-02, ...,\n",
       "          2.12499909e-02,  1.84704196e-02,  8.48987047e-03]],\n",
       "\n",
       "       [[-1.28056854e-08, -6.14672899e-08, -8.19563866e-08, ...,\n",
       "         -7.45058060e-09,  5.58793545e-09, -2.23517418e-08],\n",
       "        [-7.45058060e-09,  1.76019967e-07,  1.89989805e-07, ...,\n",
       "         -3.72529030e-09,  4.09781933e-08,  3.25962901e-08],\n",
       "        [ 5.77419996e-08,  4.28408384e-08, -9.12696123e-08, ...,\n",
       "          1.22381607e-08, -2.87545845e-08, -3.72529030e-09],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  4.31450307e-02, -4.03513685e-02, ...,\n",
       "          2.09190361e-02,  2.58018300e-02, -2.70741917e-02],\n",
       "        [ 0.00000000e+00, -8.21346045e-03, -5.26345707e-02, ...,\n",
       "          2.35338248e-02, -1.94401890e-02,  3.93868573e-02],\n",
       "        [ 0.00000000e+00, -1.16640143e-01,  4.66400832e-02, ...,\n",
       "         -4.94175106e-02,  8.28430243e-03,  8.65413249e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.15557572e-02,  6.27513230e-02,  6.00738898e-02, ...,\n",
       "          2.95793358e-02,  3.98573093e-03, -1.06651813e-01],\n",
       "        [ 4.50138375e-02, -1.03812471e-01, -7.47925118e-02, ...,\n",
       "         -3.28090526e-02,  1.18549064e-01,  3.56472470e-02],\n",
       "        [-6.22548573e-02, -1.17711034e-02, -1.01739511e-01, ...,\n",
       "         -7.86924735e-03,  4.45109233e-02,  3.64757283e-03],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -3.55063602e-02,  1.80364251e-02, ...,\n",
       "          1.16606340e-01, -5.64613938e-02, -9.01358016e-03],\n",
       "        [ 0.00000000e+00, -3.74888778e-02,  7.04760179e-02, ...,\n",
       "         -8.01215842e-02, -5.10664284e-03, -4.52907756e-02],\n",
       "        [ 0.00000000e+00, -4.34975214e-02,  7.67962858e-02, ...,\n",
       "         -5.62445298e-02,  3.30984294e-02,  5.86803677e-03]],\n",
       "\n",
       "       [[-3.72529030e-08, -3.72529030e-08, -1.41561031e-07, ...,\n",
       "          7.45058060e-09, -1.11758709e-08,  1.86264515e-08],\n",
       "        [-4.47034836e-08,  5.58793545e-09, -2.04890966e-08, ...,\n",
       "          3.35276127e-08,  0.00000000e+00,  3.72529030e-09],\n",
       "        [ 8.58203545e-02,  9.77513790e-02, -1.19271159e-01, ...,\n",
       "         -7.92726874e-02,  6.24129660e-02, -8.59977975e-02],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -1.12331502e-01, -2.94368677e-02, ...,\n",
       "         -3.00586447e-02, -6.31037131e-02,  5.84929138e-02],\n",
       "        [ 0.00000000e+00, -3.10432073e-02, -3.08895893e-02, ...,\n",
       "          2.11068131e-02,  3.16915214e-02,  1.25477284e-01],\n",
       "        [ 0.00000000e+00,  8.28439966e-02,  4.31986898e-02, ...,\n",
       "         -7.79343098e-02,  8.29579383e-02, -2.92381011e-02]],\n",
       "\n",
       "       [[-3.35276127e-08,  8.10250640e-08,  1.80676579e-07, ...,\n",
       "          5.58793545e-09, -3.84170562e-09, -6.51925802e-09],\n",
       "        [-7.45058060e-08,  5.86733222e-08,  2.32830644e-09, ...,\n",
       "          2.60770321e-08,  2.04890966e-08,  1.49011612e-08],\n",
       "        [ 1.84021682e-01,  8.35977122e-03, -1.57241315e-01, ...,\n",
       "          3.46536413e-02, -3.88627569e-03,  9.38390265e-04],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -4.91251126e-02,  5.43283187e-02, ...,\n",
       "         -7.23841414e-02,  3.05486880e-02,  3.78315002e-02],\n",
       "        [ 0.00000000e+00, -1.59866214e-01, -1.83140449e-02, ...,\n",
       "         -4.03030701e-02, -2.48217396e-02,  3.22095901e-02],\n",
       "        [ 0.00000000e+00,  2.29242519e-02, -3.68841887e-02, ...,\n",
       "          1.08069414e-02,  5.45447841e-02, -5.96818561e-03]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(v,1,2).cpu().numpy() - vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u torch.Size([30, 784, 784])\n",
      "sigma torch.Size([30, 784])\n",
      "v torch.Size([30, 784, 784])\n"
     ]
    }
   ],
   "source": [
    "u, sigma, v = torch.svd(dgdx, some=False)\n",
    "print('u',u.shape)\n",
    "print('sigma',sigma.shape)\n",
    "print('v',v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
